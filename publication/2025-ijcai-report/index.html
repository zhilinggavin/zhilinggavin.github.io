<!doctype html><html lang=en dir=ltr><head><meta charset=UTF-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.128.0"><title>Decoding Report Generators: A Cyclic Vision-Language Adapter for Counterfactual Explanations | Home</title>
<meta property="twitter:site" content="@Gavin_zhiling"><meta property="twitter:creator" content="@Gavin_zhiling"><meta name=description content="Developed a multi-modal AI model (Vision + Text) to enable controllable image manipulation via text for automated clinical diagnostics."><meta name=google-site-verification content="SXazFKEYdrkxQRjO6ofQA45n5g-Uxn_sq3vVTYYnZ9U"><meta property="og:site_name" content="Home"><meta property="og:title" content="Decoding Report Generators: A Cyclic Vision-Language Adapter for Counterfactual Explanations | Home"><meta property="og:description" content="Developed a multi-modal AI model (Vision + Text) to enable controllable image manipulation via text for automated clinical diagnostics."><meta property="og:type" content="page"><meta property="og:url" content="https://zhilinggavin.github.io/publication/2025-ijcai-report/"><meta property="og:locale" content="en"><meta property="og:image" content="https://zhilinggavin.github.io/img/gavin-social.png"><meta property="twitter:card" content="summary_large_image"><meta name=twitter:image content="https://zhilinggavin.github.io/img/gavin-social.png"><meta itemprop=name content="Decoding Report Generators: A Cyclic Vision-Language Adapter for Counterfactual Explanations"><meta itemprop=description content="Developed a multi-modal AI model (Vision + Text) to enable controllable image manipulation via text for automated clinical diagnostics."><meta itemprop=datePublished content="2024-11-08T00:00:00+00:00"><meta itemprop=dateModified content="2024-11-08T00:00:00+00:00"><meta itemprop=wordCount content="145"><script async src="https://www.googletagmanager.com/gtag/js?id=G-TY8767RX3C"></script><script>var dnt,doNotTrack=!1;if(!0&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-TY8767RX3C")}</script><!--[if IE]><script src=//html5shiv.googlecode.com/svn/trunk/html5.js></script><![endif]--><link rel="shortcut icon" href=/img/blogophonic-mark-dark.png type=image/x-icon><link rel=icon href=/img/blogophonic-mark-dark.png type=image/x-icon><link rel=stylesheet href=/style.main.min.f1c70741e5091f975b7bc4ae3a27fc1cfd20f32c1ef9a6c96197dc001901dcf4.css integrity="sha256-8ccHQeUJH5dbe8SuOif8HP0g8ywe+abJYZfcABkB3PQ=" media=screen><script src=/panelset.min.ed1ac24b6e16f4e2481e3d1d098ae66f5bc77438aef619e6e266d8ac5b00dc72.js type=text/javascript></script><script src=/main.min.5e879d1eb00c13cf4d77eb761da7fa695e6157d40cb3948ccd9da44eb8557493.js type=text/javascript></script></head><body><div class=grid-container><header class="site-header pt4 pb2 mb4 bb b--transparent ph5 headroom z-max" role=banner><nav class="site-nav db dt-l w-100" role=navigation><a class="site-brand db dtc-l v-mid link no-underline w-100 w-33-l tc tl-l" href=https://zhilinggavin.github.io/ title=Home><span class="f4 fw7">Home</span></a><div class="site-links db dtc-l v-mid w-100 w-47-l tc tr-l mt3 mt0-l ttu tracked"><a class="link f6 f5-l dib pv1 ph2" href=/about/ title="About Me">About</a>
<a class="link f6 f5-l dib pv1 ph2 active" href=/publication/ title="Research Publications">Publications</a>
<a class="link f6 f5-l dib pv1 ph2" href=/project/ title="Project Portfolio">Projects</a>
<a class="link f6 f5-l dib pv1 ph2" href=/contact/ title="Contact form">Contact</a></div></nav></header><main class="page-main pa4" role=main><section class="page-content mw7 center"><article class="post-content pa0 ph4-l"><header class=post-header><h1 class="f1 lh-solid measure-narrow mb3 fw4">Decoding Report Generators: A Cyclic Vision-Language Adapter for Counterfactual Explanations</h1><h2 class="f4 mt0 mb4 lh-title measure">Developed a multi-modal AI model (Vision + Text) to enable controllable image manipulation via text for automated clinical diagnostics.</h2><h2 class="f5 mt0 mb2 lh-title measure">International Joint Conference on Artificial Intelligence (IJCAI) 2025</h2><p class="f6 measure lh-copy mv1">By Yingying Fang, Zihao Jin, Gavin (Zhiling) Yue, et al.</p><div class="ph0 pt5"><a class="btn-links mr2 ba dib" href=https://arxiv.org/pdf/2411.05261 target=_blank rel=noopener><i class="fa fa-file-pdf fa-lg fa-fw mr2"></i>Publication</a></div></header><section class="post-body pt5 pb4"><style type=text/css>.page-main img{box-shadow:0 0 2px 2px rgba( 0,0,0,.2 );# transition: transform ease-in-out 1s}.page-main img:hover{transform:scale(1.5)}</style><img src=result.png data-fig-alt="Foundational: 1) Vision, 2) safe environment, and 3) organizing team. Design: 4) Counter bias, 5) virtual/hybrid, 6) accessibility, 7) language, 8) communication, 9) finance. Continuity: 10) pass the torch" style=width:100%><p class=caption style=text-align:left><b>Figure 1.</b> Overview of proposed Vision-Language report generator.</p><h2 id=abstract>Abstract
<a href=#abstract title="Link to heading"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>Despite significant advancements in report generation methods, a critical limitation remains: the lack of interpretability in the generated text. This paper introduces an innovative approach to enhance the explainability of text generated by report generation models. Our method employs cyclic text manipulation and visual comparison to identify and elucidate the features in the original content that influence the generated text. By manipulating the generated reports and producing corresponding images, we create a comparative framework that highlights key attributes and their impact on the text generation process. This approach not only identifies the image features aligned to the generated text but also improves transparency but also provides deeper insights into the decision-
making mechanisms of the report generation models. Our findings demonstrate the potential of this method to significantly enhance the interpretability and transparency of AI-generated reports.</p></section><footer class=post-footer><div class="post-pagination dt w-100 mt4 mb2"><a class="next dtc pl2 tr v-top fw6" href=https://zhilinggavin.github.io/publication/2025-isbi-wsss/>Enhancing Weakly Supervised Semantic Segmentation for Fibrosis via Controllable Image Generation &rarr;</a></div></footer></article></section></main><footer class="site-footer pv4 bt b--transparent ph5" role=contentinfo><nav class="db dt-l w-100"><p class="site-copyright f7 db dtc-l v-mid w-100 w-33-l tc tl-l pv2 pv0-l mv0 lh-copy">&copy; 2025 Gavin Yue, London, UK
<span class=middot-divider></span>
Made with <span xmlns:dct=http://purl.org/dc/terms/ property="dct:title"><a xmlns:dct=http://purl.org/dc/terms/ href=https://github.com/hugo-apero/ rel=dct:source>Hugo Ap√©ro</a></span>.<br>Based on <span xmlns:dct=http://purl.org/dc/terms/ property="dct:title"><a xmlns:dct=http://purl.org/dc/terms/ href=https://github.com/formspree/blogophonic-hugo rel=dct:source>Blogophonic</a></span> by <a xmlns:cc=http://creativecommons.org/ns# href=https://formspree.io property="cc:attributionName" rel=cc:attributionURL>Formspree</a>.</p><div class="site-social-links db dtc-l v-mid w-100 w-33-l tc pv2 pv0-l mv0"><div class=social-icon-links aria-hidden=true><a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href=https://www.linkedin.com/in/gavin-yue/ title target=_blank rel="me noopener"><i class="fab fa-linkedin fa-lg fa-fw"></i>
</a><a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href=https://github.com/zhilinggavin title target=_blank rel="me noopener"><i class="fab fa-github fa-lg fa-fw"></i>
</a><a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://scholar.google.com/citations?user=0w6wRvkAAAAJ&amp;hl=en" title target=_blank rel="me noopener"><i class="ai ai-google-scholar fa-lg fa-fw"></i>
</a><a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href=/CV-Gavin-ComputerVisionMIS.pdf title><i class="ai ai-cv fa-lg fa-fw"></i></a></div></div><div class="site-links f6 db dtc-l v-mid w-100 w-67-l tc tr-l pv2 pv0-l mv0"><a class="dib pv1 ph2 link" href=/contact/ title="Contact Form">Contact</a>
<a class="dib pv1 ph2 link" href=/license/ title="License Details">License</a></div></nav><script>var i,text,code,codes=document.getElementsByTagName("code");for(let e=0;e<codes.length;){if(code=codes[e],code.parentNode.tagName!=="PRE"&&code.childElementCount===0&&(text=code.textContent,/^\$[^$]/.test(text)&&/[^$]\$$/.test(text)&&(text=text.replace(/^\$/,"\\(").replace(/\$$/,"\\)"),code.textContent=text),/^\\\((.|\s)+\\\)$/.test(text)||/^\\\[(.|\s)+\\\]$/.test(text)||/^\$(.|\s)+\$$/.test(text)||/^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text))){code.outerHTML=code.innerHTML;continue}e++}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css integrity=sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js integrity=sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js integrity=sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl crossorigin=anonymous onload=renderMathInElement(document.body)></script></footer></div></body></html>