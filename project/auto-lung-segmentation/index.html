<!doctype html><html lang=en dir=ltr><head><meta charset=UTF-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.128.0"><title>Auto Lung Anatomy Segmentation | Home</title>
<meta property="twitter:site" content="@Gavin_zhiling"><meta property="twitter:creator" content="@Gavin_zhiling"><meta name=description content="Trained and Evaluated CNNs-based Segmentation Model for automated lung region segmentation."><meta name=google-site-verification content="SXazFKEYdrkxQRjO6ofQA45n5g-Uxn_sq3vVTYYnZ9U"><meta property="og:site_name" content="Home"><meta property="og:title" content="Auto Lung Anatomy Segmentation | Home"><meta property="og:description" content="Trained and Evaluated CNNs-based Segmentation Model for automated lung region segmentation."><meta property="og:type" content="page"><meta property="og:url" content="https://zhilinggavin.github.io/project/auto-lung-segmentation/"><meta property="og:locale" content="en"><meta property="og:image" content="https://zhilinggavin.github.io/project/auto-lung-segmentation/featured.webp"><meta property="twitter:card" content="summary_large_image"><meta name=twitter:image content="https://zhilinggavin.github.io/project/auto-lung-segmentation/featured.webp"><meta itemprop=name content="Auto Lung Anatomy Segmentation"><meta itemprop=description content="Automatic Lung segmentation Introduction The automatic segmentation of the lung region in chest X-rays (CXR) aids doctors in diagnosing various lung diseases. However, severe lung deformities and indistinct lung boundaries caused by serious conditions can lead to errors in the segmentation model.
Data and task description Dataset consists of collected from public available chest X-Ray (CXR) images. Overall amount of images is 800 meanwhile labeled only 704 of them. Whole dataset was randomly divided into train (0."><meta itemprop=datePublished content="2024-07-18T00:00:00+00:00"><meta itemprop=dateModified content="2024-07-18T00:00:00+00:00"><meta itemprop=wordCount content="451"><meta itemprop=image content="https://zhilinggavin.github.io/project/auto-lung-segmentation/featured.webp"><meta itemprop=keywords content="AI,Computer Vision,Medical"><script async src="https://www.googletagmanager.com/gtag/js?id=G-TY8767RX3C"></script><script>var dnt,doNotTrack=!1;if(!0&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-TY8767RX3C")}</script><!--[if IE]><script src=//html5shiv.googlecode.com/svn/trunk/html5.js></script><![endif]--><link rel="shortcut icon" href=/img/blogophonic-mark-dark.png type=image/x-icon><link rel=icon href=/img/blogophonic-mark-dark.png type=image/x-icon><link rel=stylesheet href=/style.main.min.f1c70741e5091f975b7bc4ae3a27fc1cfd20f32c1ef9a6c96197dc001901dcf4.css integrity="sha256-8ccHQeUJH5dbe8SuOif8HP0g8ywe+abJYZfcABkB3PQ=" media=screen><script src=/panelset.min.ed1ac24b6e16f4e2481e3d1d098ae66f5bc77438aef619e6e266d8ac5b00dc72.js type=text/javascript></script><script src=/main.min.5e879d1eb00c13cf4d77eb761da7fa695e6157d40cb3948ccd9da44eb8557493.js type=text/javascript></script></head><body><div class=grid-container><header class="site-header pt4 pb2 mb4 bb b--transparent ph5 headroom z-max" role=banner><nav class="site-nav db dt-l w-100" role=navigation><a class="site-brand db dtc-l v-mid link no-underline w-100 w-33-l tc tl-l" href=https://zhilinggavin.github.io/ title=Home><span class="f4 fw7">Home</span></a><div class="site-links db dtc-l v-mid w-100 w-47-l tc tr-l mt3 mt0-l ttu tracked"><a class="link f6 f5-l dib pv1 ph2" href=/about/ title="About Me">About</a>
<a class="link f6 f5-l dib pv1 ph2" href=/publication/ title="Research Publications">Publications</a>
<a class="link f6 f5-l dib pv1 ph2 active" href=/project/ title="Project Portfolio">Projects</a>
<a class="link f6 f5-l dib pv1 ph2" href=/contact/ title="Contact form">Contact</a></div></nav></header><main class="page-main pa4" role=main><section class="page-content mw7 center"><article class="post-content pa0 ph4-l"><header class=post-header><h1 class="f1 lh-solid measure-narrow mb3 fw4">Auto Lung Anatomy Segmentation</h1><h2 class="f4 mt0 mb4 lh-title measure">Trained and Evaluated CNNs-based Segmentation Model for automated lung region segmentation.</h2><p class="f6 measure lh-copy mv1">By Gavin Yue in <a href=https://zhilinggavin.github.io/categories/ai>AI</a> <a href=https://zhilinggavin.github.io/categories/computer-vision>Computer Vision</a> <a href=https://zhilinggavin.github.io/categories/medical>Medical</a></p><div class="ph0 pt5"><a class="btn-links mr2 ba dib" href=https://github.com/zhilinggavin/auto_lung_segmentation target=_blank rel=noopener><i class="fab fa-github fa-lg fa-fw mr2"></i>code</a></div></header><section class="post-body pt5 pb4"><h1 id=automatic-lung-segmentation>Automatic Lung segmentation
<a href=#automatic-lung-segmentation title="Link to heading"></a></h1><h2 id=introduction>Introduction
<a href=#introduction title="Link to heading"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>The automatic segmentation of the lung region in chest X-rays (CXR) aids doctors in diagnosing various lung diseases. However, severe lung deformities and indistinct lung boundaries caused by serious conditions can lead to errors in the segmentation model.</p><h2 id=data-and-task-description>Data and task description
<a href=#data-and-task-description title="Link to heading"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p><img src=images/data-example.png alt=data-example></p><p>Dataset consists of collected from public available chest X-Ray (CXR) images.
Overall amount of images is 800 meanwhile labeled only 704 of them.
Whole dataset was randomly divided into train (0.8 of total) validation (0.1 splited from train) and test parts.</p><p>The main task is to implement pixel-wise segmentation on the available data to detect lung area.</p><h2 id=proposed-solution>Proposed solution
<a href=#proposed-solution title="Link to heading"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>The most obvious solution for semantic segmentation problems is UNet - fully convolutional network with an encoder-decoder path. High-resolution features from the contracting path are combined with the upsampled output in order to predict more precise output based on this information, which is the main idea of this architecture.</p><p>Softmax function was applied to model output and negative log-likelihood loss was used to train network.
Optimization criterion - Adam with 0.0005 learning rate.</p><p>Some kinds of data augmentation were used: horizontal and vertical shift, minor zoom and padding.
All images and masks were resized to 512x512 size before passing the network.
To improve performance was decided to use pretrained on ImageNet encoder from vgg11 network.
This approach slightly improves performance and greatly accelerate network convergence.
Vanilla unet configuration doesn&rsquo;t have batch normalization. Nowadays it is used almost every time, so it was added to improve network convergence too.
Such network configuration outperforms other variations of unet without batch norm and pretrained weights on validation dataset so it was chosen for final evaluation</p><p>Networks were trained on a batch of 4 images during more than 50 epochs on average.</p><p>After 40 epoch network stops to improve validation score and network began to overfit.</p><ul><li>unet-2v: simple unet + augmentation</li></ul><pre tabindex=0><code>test loss: 0.0634, test jaccard: 0.9110, test dice: 0.9520
</code></pre><ul><li>unet-6v: pretrained vgg11 encoder + batch_norm + bilinear upscale + augmentation</li></ul><pre tabindex=0><code>test loss: 0.0530, test jaccard: 0.9268, test dice: 0.9611
</code></pre><h2 id=evaluation>Evaluation
<a href=#evaluation title="Link to heading"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>For evaluation of model output was Jaccard and Dice metrics, well known for such kind of computer vision tasks.</p><p>Evaluation was performed on test dataset, which was not used during training phase.</p><p>There are the best-achived results: Jaccard score - <strong>0.9268</strong>, Dice score - <strong>0.9611</strong>.</p><p>Some you obtained results could see on the figure below.</p><p><img src=images/obtained-results.png alt=obtained-results></p><h2 id=further-work>Further Work
<a href=#further-work title="Link to heading"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><h3 id=more-image-processing-samples-for-future-task>More Image Processing Samples for Future Task
<a href=#more-image-processing-samples-for-future-task title="Link to heading"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h3><p><img src=images/box-sample-Cardiomegaly.png alt=obtained-results></p><h2 id=references>References
<a href=#references title="Link to heading"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><ul><li><a href=https://arxiv.org/pdf/1505.04597.pdf target=_blank rel=noopener>https://arxiv.org/pdf/1505.04597.pdf</a> - U-Net: Convolutional Networks for Biomedical Image Segmentation</li><li><a href=https://arxiv.org/pdf/1811.12638.pdf target=_blank rel=noopener>https://arxiv.org/pdf/1811.12638.pdf</a> - Towards Robust Lung Segmentation in Chest Radiographs with Deep Learning</li><li><a href=https://arxiv.org/pdf/1801.05746.pdf target=_blank rel=noopener>https://arxiv.org/pdf/1801.05746.pdf</a> - TernausNet: U-Net with VGG11 Encoder Pre-Trained on ImageNet for Image Segmentation</li><li><a href=https://arxiv.org/pdf/1708.00710.pdf target=_blank rel=noopener>https://arxiv.org/pdf/1708.00710.pdf</a> - Accurate Lung Segmentation via Network-WiseTraining of Convolutional Networks</li></ul><details closed class="f6 fw7 input-reset"><dl class="f6 lh-copy"><dt class=fw7>Posted on:</dt><dd class="fw5 ml0">July 18, 2024</dd></dl><dl class="f6 lh-copy"><dt class=fw7>Length:</dt><dd class="fw5 ml0">3 minute read, 451 words</dd></dl><dl class="f6 lh-copy"><dt class=fw7>Categories:</dt><dd class="fw5 ml0"><a href=https://zhilinggavin.github.io/categories/ai>AI</a> <a href=https://zhilinggavin.github.io/categories/computer-vision>Computer Vision</a> <a href=https://zhilinggavin.github.io/categories/medical>Medical</a></dd></dl><dl class="f6 lh-copy"><dt class=fw7>See Also:</dt></dl></details></section><footer class=post-footer><div class="post-pagination dt w-100 mt4 mb2"><a class="prev dtc pr2 tl v-top fw6" href=https://zhilinggavin.github.io/project/diffusion-wsss/>&larr; DiffSeg: Diffusion-Based Weakly Supervised Segmentation for Fibrosis</a>
<a class="next dtc pl2 tr v-top fw6" href=https://zhilinggavin.github.io/project/explanable-ai/>Explainable AI - Controlable Image Generation &rarr;</a></div></footer></article></section></main><footer class="site-footer pv4 bt b--transparent ph5" role=contentinfo><nav class="db dt-l w-100"><p class="site-copyright f7 db dtc-l v-mid w-100 w-33-l tc tl-l pv2 pv0-l mv0 lh-copy">&copy; 2025 Gavin Yue, London, UK
<span class=middot-divider></span>
Made with <span xmlns:dct=http://purl.org/dc/terms/ property="dct:title"><a xmlns:dct=http://purl.org/dc/terms/ href=https://github.com/hugo-apero/ rel=dct:source>Hugo Ap√©ro</a></span>.<br>Based on <span xmlns:dct=http://purl.org/dc/terms/ property="dct:title"><a xmlns:dct=http://purl.org/dc/terms/ href=https://github.com/formspree/blogophonic-hugo rel=dct:source>Blogophonic</a></span> by <a xmlns:cc=http://creativecommons.org/ns# href=https://formspree.io property="cc:attributionName" rel=cc:attributionURL>Formspree</a>.</p><div class="site-social-links db dtc-l v-mid w-100 w-33-l tc pv2 pv0-l mv0"><div class=social-icon-links aria-hidden=true><a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href=https://www.linkedin.com/in/gavin-yue/ title target=_blank rel="me noopener"><i class="fab fa-linkedin fa-lg fa-fw"></i>
</a><a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href=https://github.com/zhilinggavin title target=_blank rel="me noopener"><i class="fab fa-github fa-lg fa-fw"></i>
</a><a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://scholar.google.com/citations?user=0w6wRvkAAAAJ&amp;hl=en" title target=_blank rel="me noopener"><i class="ai ai-google-scholar fa-lg fa-fw"></i>
</a><a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href=/CV-Gavin-ComputerVisionMIS.pdf title><i class="ai ai-cv fa-lg fa-fw"></i></a></div></div><div class="site-links f6 db dtc-l v-mid w-100 w-67-l tc tr-l pv2 pv0-l mv0"><a class="dib pv1 ph2 link" href=/contact/ title="Contact Form">Contact</a>
<a class="dib pv1 ph2 link" href=/license/ title="License Details">License</a></div></nav><script>var i,text,code,codes=document.getElementsByTagName("code");for(let e=0;e<codes.length;){if(code=codes[e],code.parentNode.tagName!=="PRE"&&code.childElementCount===0&&(text=code.textContent,/^\$[^$]/.test(text)&&/[^$]\$$/.test(text)&&(text=text.replace(/^\$/,"\\(").replace(/\$$/,"\\)"),code.textContent=text),/^\\\((.|\s)+\\\)$/.test(text)||/^\\\[(.|\s)+\\\]$/.test(text)||/^\$(.|\s)+\$$/.test(text)||/^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text))){code.outerHTML=code.innerHTML;continue}e++}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css integrity=sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js integrity=sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js integrity=sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl crossorigin=anonymous onload=renderMathInElement(document.body)></script></footer></div></body></html>